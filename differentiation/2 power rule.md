# 2ï¸âƒ£ Power Rule

## ğŸ”¹ Big Idea

The Power Rule makes taking derivatives very easy.

If:

f(x) = xâ¿

Then:

d/dx (xâ¿) = n xâ¿â»Â¹

Thatâ€™s it. Just:

1. Bring the power down  
2. Subtract 1 from the power  

---

## ğŸ§  Why Do We Need This?

Using the definition of derivative every time is slow.

Example:

To compute derivative of xÂ² using limit definition takes many steps.

The Power Rule gives the answer instantly.

---

## ğŸ§  Basic Examples

### Example 1

f(x) = xÂ²  

Using power rule:

d/dx (xÂ²) = 2xÂ¹ = 2x

---

### Example 2

f(x) = xÂ³  

d/dx (xÂ³) = 3xÂ²

---

### Example 3

f(x) = xâµ  

d/dx (xâµ) = 5xâ´

---

### Example 4

f(x) = xÂ¹â°  

d/dx (xÂ¹â°) = 10xâ¹

---

## ğŸ§  What About Square Root?

Remember:

âˆšx = x^(1/2)

So:

d/dx (x^(1/2)) = (1/2)x^(-1/2)

Which can also be written as:

1 / (2âˆšx)

---

## ğŸ§  What About 1/x ?

Rewrite first:

1/x = xâ»Â¹

Now apply power rule:

d/dx (xâ»Â¹) = -1 xâ»Â²

= -1 / xÂ²

---

## ğŸ§  Important Pattern

Original â†’ Derivative

xÂ² â†’ 2x  
xÂ³ â†’ 3xÂ²  
xâ´ â†’ 4xÂ³  
xâ¿ â†’ n xâ¿â»Â¹  

Power decreases by 1 every time.

---

## ğŸ¤– Why Power Rule Matters in Deep Learning

In neural networks:

Loss functions often contain:

- xÂ²  
- xÂ³  
- polynomial terms  

Example:

Loss = (prediction âˆ’ target)Â²

To minimize loss, we take derivative.

Without power rule, training neural networks would be slow and messy.

Power rule makes gradient computation fast.

---

## ğŸ§© Intuition Summary

Power Rule says:

If f(x) = xâ¿

Then:

Derivative = n xâ¿â»Â¹

Just:

âœ” Bring exponent down  
âœ” Reduce exponent by 1  

---

## ğŸ”¹ Practice Questions

1. d/dx (xâ·) = ?  
2. d/dx (xâ´) = ?  
3. d/dx (xâ»Â³) = ?  

Try to solve before checking answer:

Answers:

1. 7xâ¶  
2. 4xÂ³  
3. -3xâ»â´  